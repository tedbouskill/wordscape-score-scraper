{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Prototypes\n",
    "\n",
    "Rerun the first code cell to reload the files if new files are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ipynb package\n",
    "#%pip install ipynb\n",
    "\n",
    "# Base code for all notebooks in the same folder\n",
    "from ipynb.fs.full.common import load_files, reload_packages, setup # type: ignore\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload Packages()\n",
    "\n",
    "Rerun the cell below this one to reload common packages in repo_packages or workspace_packages if they change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading packages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload_packages()\n",
    "\n",
    "import cv2 # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import pytesseract # type: ignore\n",
    "import io\n",
    "\n",
    "from cls_img_tools import ImageTools\n",
    "from cls_string_helpers import StringHelpers\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter # type: ignore\n",
    "\n",
    "import os\n",
    "\n",
    "def no_op():\n",
    "    pass\n",
    "\n",
    "def resize_image_pillow(image_path: str, new_width: int=1200):\n",
    "    with Image.open(image_path) as img:\n",
    "        original_width, original_height = img.size\n",
    "        aspect_ratio = original_height / original_width\n",
    "        new_height = int(aspect_ratio * new_width)\n",
    "\n",
    "        resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        return resized_img, new_height\n",
    "\n",
    "def resize_image_opencv(image_path: str, new_width: int = 1200) -> np.ndarray:\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path) #, cv2.IMREAD_UNCHANGED)\n",
    "    #display_image_opencv(img)\n",
    "\n",
    "    #image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    # Normalize the 16-bit image to 8-bit\n",
    "    #image_8bit = cv2.convertScaleAbs(img, alpha=(255.0/65535.0))\n",
    "    #display_image_opencv(image_8bit)\n",
    "\n",
    "    # Get the original dimensions\n",
    "    original_height, original_width = img.shape[:2]\n",
    "\n",
    "    # Calculate the new dimensions\n",
    "    aspect_ratio = original_height / original_width\n",
    "    new_height = int(aspect_ratio * new_width)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    #display_image_opencv(resized_img)\n",
    "\n",
    "    return resized_img, new_height\n",
    "\n",
    "def crop_image_opencv(image: np.ndarray, x: int, y: int, width: int, height: int) -> np.ndarray:\n",
    "    # Crop the image using array slicing\n",
    "    cropped_img = image[y:y+height, x:x+width]\n",
    "    return cropped_img\n",
    "\n",
    "def enhance_image(img, scale=2) -> Image.Image:\n",
    "    img = img.convert('L')  # Convert the image to grayscale\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    img = img.point(lambda x: 0 if x < 225 else 255, '1')\n",
    "\n",
    "    # Resize the image\n",
    "    img = img.resize((img.width * scale, img.height * scale), Image.LANCZOS)\n",
    "\n",
    "    # Sharpen the image\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "    return img\n",
    "\n",
    "def adjust_gamma(image, gamma=1.5):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255\n",
    "                    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def enhance_image_opencv(img, scale=2) -> np.ndarray:\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 1: Enhance contrast with CLAHE\n",
    "    #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    #image = clahe.apply(image)\n",
    "\n",
    "    # Step 2: Apply gamma correction\n",
    "    image = adjust_gamma(image, gamma=1.5)\n",
    "\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def convert_to_black_and_white_opencv(image: np.ndarray, threshold: int = 128) -> np.ndarray:\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def convert_non_white_to_black_opencv(image, threshold=200):\n",
    "    \"\"\"\n",
    "    Convert non-white pixels to black in the given image using OpenCV.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a mask for pixels that are above the threshold\n",
    "    mask = gray > threshold\n",
    "\n",
    "    # Create an output image with the same shape as the input image, initialized to black\n",
    "    output = np.zeros_like(image)\n",
    "\n",
    "    # Set the pixels that are above the threshold in the original image to white in the output image\n",
    "    output[mask] = [255, 255, 255]\n",
    "\n",
    "    return output\n",
    "\n",
    "def is_white(pixel, threshold=225):\n",
    "    r, g, b = pixel\n",
    "    return r > threshold and g > threshold and b > threshold\n",
    "\n",
    "def convert_non_white_to_black(image, threshold=225):\n",
    "    # Ensure the image is in RGB mode\n",
    "    img = image.convert('RGB')\n",
    "\n",
    "    # Create a new image with the same size\n",
    "    new_img = Image.new('RGB', img.size)\n",
    "\n",
    "    # Process each pixel\n",
    "    for x in range(img.width):\n",
    "        for y in range(img.height):\n",
    "            pixel = img.getpixel((x, y))\n",
    "            if is_white(pixel):\n",
    "                new_img.putpixel((x, y), (255, 255, 255))  # Keep white pixels as white\n",
    "            else:\n",
    "                new_img.putpixel((x, y), (0, 0, 0))  # Convert non-white pixels to black\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def display_image(img, title=\"Image\", rotate=0):\n",
    "    # Rotate the image 90 degrees clockwise for display\n",
    "    img = img.rotate(rotate, expand=True)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "def display_image_opencv(img, title=\"Image\"):\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in /Users/tedbouskill/Repos/MyGitHub/wordscape-score-scraper/prototypes/../png_samples/team_helps_scores\n",
      "Processing /Users/tedbouskill/Repos/MyGitHub/wordscape-score-scraper/prototypes/../png_samples/team_helps_scores/2025-01-05-02.png with new height: 2596\n",
      "Length of player results: 9\n",
      "Length of player helps: 6\n",
      "Length of player stars: 9\n",
      "Player: cariann - Helps: 26 - Stars: 1,165,394\n",
      "Player: Laura - Helps: 14 - Stars: 1,162,651\n",
      "Player: gardener - Helps: 44 - Stars: 1,115,938\n",
      "Player: Punches616 - Helps: 0 - Stars: 1,095,956\n",
      "Player: chibong - Helps: 0 - Stars: 1,071,979\n",
      "Player: Quinn - Helps: 17 - Stars: 1,019,510\n",
      "Player: Stranger - Helps: 40 - Stars: 1,000,265\n",
      "Player: jon - Helps: 0 - Stars: 936,822\n",
      "Player: Silev - Helps: 64 - Stars: 884,631\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import easyocr\n",
    "\n",
    "# Initialize EasyOCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "files = []\n",
    "files = load_files(\"../png_samples/team_helps_scores\")\n",
    "\n",
    "for img_file in files:\n",
    "    img, new_height = resize_image_opencv(img_file)\n",
    "\n",
    "    print(f\"Processing {img_file} with new height: {new_height}\")\n",
    "\n",
    "    player_results = []\n",
    "\n",
    "    offset_height = 600\n",
    "    players_img = crop_image_opencv(img, 300, offset_height, 440, new_height - offset_height) # Only player tags\n",
    "    players_img = convert_non_white_to_black_opencv(players_img, 225)\n",
    "    #display_image_opencv(players_img, title=\"Players Image\")\n",
    "\n",
    "    results = reader.readtext(players_img, mag_ratio=2.0)\n",
    "    for box, text, confidence in results:\n",
    "        if box[0][0] < 50:\n",
    "            player_results.append((box, text, confidence))\n",
    "        #print(f\"Player: {player[1]} - Box y {player[0][0][1]}\")\n",
    "\n",
    "    player_helps = []\n",
    "\n",
    "    helps_img = crop_image_opencv(img, 740, offset_height, 150, new_height - offset_height)\n",
    "    helps_img = convert_non_white_to_black_opencv(helps_img, 245)\n",
    "    #display_image_opencv(helps_img, title=\"Helps Image\")\n",
    "    results = reader.readtext(helps_img, mag_ratio=2.0, allowlist=\"0123456789\")\n",
    "    for box, text, confidence in results:\n",
    "        player_helps.append((box, text, confidence))\n",
    "        #print(f\"Helps: {help[1]} - Box y {help[0][0][1]}\")\n",
    "\n",
    "    player_stars = []\n",
    "\n",
    "    stars_img = crop_image_opencv(img, 890, offset_height, 250, new_height - offset_height)\n",
    "    stars_img = convert_non_white_to_black_opencv(stars_img, 245)\n",
    "    #display_image_opencv(stars_img, title=\"Stars Image\")\n",
    "    results = reader.readtext(stars_img, mag_ratio=2.0, allowlist=\"0123456789,\")\n",
    "    for box, text, confidence in results:\n",
    "        player_stars.append((box, text, confidence))\n",
    "        #print(f\"Stars: {text} - Box y {box[0][1]}\")\n",
    "\n",
    "    print(f\"Length of player results: {len(player_results)}\")\n",
    "    print(f\"Length of player helps: {len(player_helps)}\")\n",
    "    print(f\"Length of player stars: {len(results)}\")\n",
    "\n",
    "    # Match numeric values with text values based on y-coordinate\n",
    "    matches = []\n",
    "    unmatched = []\n",
    "    for player_text_box, player_text, player_text_confidence in player_results:\n",
    "        player_y = player_text_box[0][1]  # y-coordinate of the top-left corner of the text box\n",
    "        helps_stars = (None, None)\n",
    "        for help_text_box, help_text, help_text_confidence in player_helps:\n",
    "            help_y = help_text_box[0][1]  # y-coordinate of the top-left corner of the numeric box\n",
    "            if -40 <= (player_y - help_y) <= 25:\n",
    "                helps_stars = (help_text, None)\n",
    "                break;\n",
    "\n",
    "        # if we didn't find a Helps match it's because it was 0 which EasyOCR is not recognizing\n",
    "        if helps_stars[0] is None:\n",
    "            helps_stars = (0, None)\n",
    "\n",
    "        for star_text_box, star_text, star_text_confidence in results:\n",
    "            star_y = star_text_box[0][1]\n",
    "            if -40 <= (player_y - star_y) <= 25:\n",
    "                helps_stars = (helps_stars[0], star_text)\n",
    "                break\n",
    "\n",
    "        if helps_stars[1] is None:\n",
    "            unmatched.append((player_text, helps_stars))\n",
    "        else:\n",
    "            matches.append((player_text, helps_stars))\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"Player: {match[0]} - Helps: {match[1][0]} - Stars: {match[1][1]}\")\n",
    "\n",
    "for unmatch in unmatched:\n",
    "    print(f\"Unmatched: {unmatch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype for Import Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in /Users/tedbouskill/Repos/MyGitHub/wordscape-score-scraper/prototypes/../png_samples/weekend_scores\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "import easyocr\n",
    "\n",
    "from re import S\n",
    "from tokenize import String\n",
    "from sympy import O # type: ignore\n",
    "\n",
    "# Initialize EasyOCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "min_score_x = 1200\n",
    "\n",
    "files = []\n",
    "files = load_files(\"../png_samples/weekend_scores\")\n",
    "\n",
    "for img_file in files:\n",
    "    if \"reduced\" in img_file or \"IMG\" in img_file:\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {img_file}\")\n",
    "\n",
    "    img, new_height = resize_image_opencv(img_file)\n",
    "    #display_image_opencv(img, title=\"Original Image\")\n",
    "\n",
    "    #img = enhance_image_opencv(img)\n",
    "\n",
    "    #header_img = img.crop((0, 0, 1200, 1050))\n",
    "    #display_image(header_img, title=\"Header Image\")\n",
    "\n",
    "    state_img = crop_image_opencv(img, 450, 680, 300, 100)\n",
    "    state_img = convert_non_white_to_black_opencv(state_img)\n",
    "    state_txt = pytesseract.image_to_string(state_img)\n",
    "    if state_txt is not None:\n",
    "        state_txt = state_txt.strip()\n",
    "        print(f\"State: {state_txt}\")\n",
    "    #display_image_opencv(state_img, title=\"State Image\")\n",
    "\n",
    "    # If tournament fininshed, the rank image is present\n",
    "    if state_txt == \"FINISHED\":\n",
    "        rank_img = crop_image_opencv(img, 100, 540, 200, 110)\n",
    "        rank_img = convert_non_white_to_black_opencv(rank_img)\n",
    "        rank_txt = pytesseract.image_to_string(rank_img).strip()\n",
    "        print(f\"Rank: {rank_txt}\")\n",
    "        #display_image_opencv(rank_img, title=\"Rank Image\")\n",
    "\n",
    "    #ranks_img = crop_image_opencv(img, 40, 1000, 110, new_height - 1000)\n",
    "    #ranks_img = enhance_image_opencv(ranks_img)\n",
    "    #results = reader.readtext(ranks_img)\n",
    "    #for box, text, confidence in results:\n",
    "    #    print(f\"Box: {box}, Text: {text}, Confidence: {confidence}\")\n",
    "    #display_image_opencv(ranks_img, title=\"Ranks Image\")\n",
    "\n",
    "    player_results = []\n",
    "    score_results = []\n",
    "    results = []\n",
    "\n",
    "    players_img = crop_image_opencv(img, 300, 1050, 600, new_height - 1050) # Only player tags\n",
    "    #players_img = crop_image_opencv(img, 300, 1050, 900, new_height - 1050) # Player and score tags\n",
    "    players_img = convert_non_white_to_black_opencv(players_img, 225)\n",
    "    display_image_opencv(players_img, title=\"Players Image\")\n",
    "    results = reader.readtext(players_img, mag_ratio=2.0)\n",
    "    for box, text, confidence in results:\n",
    "        print(f\"Text: {text}, Box: {box}, Confidence: {confidence}\")\n",
    "        # If the y is less than 100, then it is the player name\n",
    "        if box[0][0] < 50:\n",
    "            player_results.append((box, text, confidence))\n",
    "\n",
    "        if box[0][0] > 650: # and (StringHelpers.is_all_numeric(text) or \"O\" in text or \"o\" in text):\n",
    "            if box[0][0] < min_score_x:\n",
    "                min_score_x = box[0][0]\n",
    "            score_results.append((box, text, confidence))\n",
    "\n",
    "    scores_img = crop_image_opencv(img, 900, 1050, 300, new_height - 1050)\n",
    "    scores_img = convert_non_white_to_black_opencv(scores_img, 222)\n",
    "    scores_img = adjust_gamma(scores_img, gamma=5.1)\n",
    "    display_image_opencv(scores_img, title=\"Scores Image\")\n",
    "    #results = reader.detect(scores_img, mag_ratio=4.0)\n",
    "    #for bbox in results[0]:\n",
    "    #    print(bbox)  # Print bounding boxes to check if zeros are detected\n",
    "\n",
    "    results = reader.readtext(scores_img, detail=1, mag_ratio=4.0, allowlist=\"0123456789oO\", blocklist=\".,!@#$%^&*()\")\n",
    "    for box, text, confidence in results:\n",
    "        print(f\"Text: {text}, Box: {box}, Confidence: {confidence}\")\n",
    "        score_results.append((box, text, confidence))\n",
    "    tesseract_results = pytesseract.image_to_string(scores_img, config='--psm 7 -c tessedit_char_whitelist=0123456789Oo')\n",
    "    print(f\"Tesseract: {tesseract_results}\")\n",
    "\n",
    "    print(\"Length of player results: \", len(player_results))\n",
    "    print(\"Length of score results: \", len(score_results))\n",
    "    print(\"Min score x: \", min_score_x)\n",
    "\n",
    "     # Match numeric values with text values based on y-coordinate\n",
    "    matches = []\n",
    "    unmatched = []\n",
    "    for text_box, text, text_confidence in player_results:\n",
    "        text_y = text_box[0][1]  # y-coordinate of the top-left corner of the text box\n",
    "        matched = False\n",
    "        for num_box, num_text, num_confidence in score_results:\n",
    "            num_y = num_box[0][1]  # y-coordinate of the top-left corner of the numeric box\n",
    "            if 0 < abs(num_y - text_y) < 65:\n",
    "                matches.append((text, num_text))\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            unmatched.append((text, text_confidence))\n",
    "\n",
    "    # Print matched results\n",
    "    for text, num in matches:\n",
    "        print(f\"Text: {text}, Numeric: {num}\")\n",
    "\n",
    "    # Print unmatched results\n",
    "    print(\"Unmatched:\")\n",
    "    for text, confidence in unmatched:\n",
    "        print(f\"Text: {text}, Confidence: {confidence}\")\n",
    "\n",
    "    #display_image_opencv(players_img, title=\"Players Image\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Found Metrics using EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX IMAGE HEIGHT 2596\n",
      "{'CONTINUE', 'RANKING', 'REWARD', 'RANK'}\n",
      "{'prizes will be divided by 50.', 'lichi', 'Dewey', 'TEAM -OURNAENT', '25,000', 'mike', '~EAV TOURNAMEN-', 'zmewis', 'dinogirl', \"Win prizes based on your team's stars! The team\", 'keymony', '1d 4h', 'allenge yourselfl', 'chibong', 'xi Solitaire Trigeak', 'kay', 'JoCo', '1d4h', 'Not Participating', 'Stranger', 'butterfly', 'allongo vcursomi', 'Goose', 'spudly', 'ki Solitaire Tripeak', 'Mar', 'Siley', 'Murphy', 'tedbilly', 'cariann', 'Suriel', 'RNnCinci', \"Win prizes based on your team'$ stars! The team\", 'Jay'}\n",
      "Label,min_height,min_width,max_height,max_width\n",
      "TEAM TOURNAMENT,177,178,280,1025\n",
      "FINISHED,690,481,750,722\n",
      "TEAMMATES,843,668,1041,1080\n",
      "FIRST,1081,81,1243,105\n",
      "SECOND,1288,77,1456,109\n",
      "THIRD,1500,77,1665,109\n",
      "SCORES,629,925,2540,1114\n",
      "TEAM RANK,542,144,633,270\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import re\n",
    "\n",
    "import cls_string_helpers as StringHelpers\n",
    "\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from hmac import new\n",
    "\n",
    "def get_min_max_values(boxes):\n",
    "    if not boxes:\n",
    "        return None, None, None, None\n",
    "\n",
    "    min_height = min(min(box[0][1], box[1][1], box[2][1], box[3][1]) for box in boxes)\n",
    "    min_width = min(min(box[0][0], box[1][0], box[2][0], box[3][0]) for box in boxes)\n",
    "    max_height = max(max(box[0][1], box[1][1], box[2][1], box[3][1]) for box in boxes)\n",
    "    max_width = max(max(box[0][0], box[1][0], box[2][0], box[3][0]) for box in boxes)\n",
    "\n",
    "    return min_height, min_width, max_height, max_width\n",
    "\n",
    "# Initialize EasyOCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "tt_ds = set()\n",
    "ts_dims = set()\n",
    "team_rank_dims = set()\n",
    "teammates_dims = set()\n",
    "first_dims = set()\n",
    "second_dims = set()\n",
    "third_dims = set()\n",
    "scores_dims = set()\n",
    "\n",
    "max_image_heights = []\n",
    "unique_strings = set()\n",
    "unique_uppercase_strings = set()\n",
    "\n",
    "files = []\n",
    "files = load_files(\"../png_samples/weekend_scores\")\n",
    "\n",
    "for img_file in files:\n",
    "    temp_path, new_height = resize_image_pillow(img_file)\n",
    "    max_image_heights.append(new_height)\n",
    "\n",
    "    results = reader.readtext(temp_path)\n",
    "\n",
    "    for box, text, confidence in results:\n",
    "        box_tuple = tuple(map(tuple, box))  # Convert list of lists to tuple of tuples\n",
    "\n",
    "        if StringHelpers.is_all_uppercase(text):\n",
    "            if text == \"TEAM TOURNAMENT\":\n",
    "                tt_ds.add(box_tuple)\n",
    "                continue\n",
    "            if text == \"FINISHED\":\n",
    "                ts_dims.add(box_tuple)\n",
    "                continue\n",
    "            if text == \"TEAMMATES\":\n",
    "                teammates_dims.add(box_tuple)\n",
    "                continue\n",
    "\n",
    "            similarity_ratio = fuzz.ratio(text, \"TEAM TOURNAMENT\")\n",
    "            if similarity_ratio > 75:\n",
    "                tt_ds.add(box_tuple)\n",
    "                continue\n",
    "\n",
    "            unique_uppercase_strings.add(text)\n",
    "\n",
    "            continue\n",
    "\n",
    "        if StringHelpers.is_all_numeric(text):\n",
    "            nbr = StringHelpers.convert_to_integer(text)\n",
    "\n",
    "            if nbr > 50 and box[0][0] > 600:\n",
    "                scores_dims.add(box_tuple)\n",
    "                continue\n",
    "\n",
    "            if text == \"1\":\n",
    "                first_dims.add(box_tuple)\n",
    "                continue\n",
    "            if text == \"2\":\n",
    "                second_dims.add(box_tuple)\n",
    "                continue\n",
    "            if text == \"3\":\n",
    "                third_dims.add(box_tuple)\n",
    "                continue\n",
    "\n",
    "            continue\n",
    "\n",
    "        if text.startswith(\"#\"):\n",
    "            team_rank_dims.add(box_tuple)\n",
    "            continue\n",
    "\n",
    "        unique_strings.add(text)\n",
    "\n",
    "        #print(f\"\\tBox: {box_tuple}, Text: {text}, Confidence: {confidence}\")\n",
    "\n",
    "    os.remove(temp_path)\n",
    "\n",
    "max_image_height = max(max_image_heights)\n",
    "print(f\"MAX IMAGE HEIGHT {max_image_height}\")\n",
    "\n",
    "# Collect min/max values for each set of boxes\n",
    "data = [\n",
    "    (\"TEAM TOURNAMENT\", *get_min_max_values(tt_ds)),\n",
    "    (\"FINISHED\", *get_min_max_values(ts_dims)),\n",
    "    (\"TEAMMATES\", *get_min_max_values(teammates_dims)),\n",
    "    (\"FIRST\", *get_min_max_values(first_dims)),\n",
    "    (\"SECOND\", *get_min_max_values(second_dims)),\n",
    "    (\"THIRD\", *get_min_max_values(third_dims)),\n",
    "    (\"SCORES\", *get_min_max_values(scores_dims)),\n",
    "    (\"TEAM RANK\", *get_min_max_values(team_rank_dims))\n",
    "]\n",
    "\n",
    "print(unique_uppercase_strings)\n",
    "print(unique_strings)\n",
    "\n",
    "# Print CSV formatted output\n",
    "print(\"Label,min_height,min_width,max_height,max_width\")\n",
    "for row in data:\n",
    "    print(\",\".join(map(str, row)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
